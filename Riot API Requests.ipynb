{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import requests \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set API Key (it changes every 24h!)\n",
    "\n",
    "API_key = 'RGAPI-2c656568-80f9-431f-bc10-5516b90facaa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the URL for D1 in KR\n",
    "\n",
    "urls = ['https://kr.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/DIAMOND/I?', 'https://kr.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/DIAMOND/II?']\n",
    "\n",
    "# initializing all the pages we want to go through \n",
    "\n",
    "pages = [\"I\",\"II\",\"III\",\"IV\",\"V\",\"VI\",\"VII\",\"VIII\",\"IX\",\"X\",\"XI\",\"XII\",\"XIII\",'XIV','XV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function that will return us all summoner ids from the leagues below masters\n",
    "\n",
    "def get_summoner_ids(pages, url):\n",
    "\n",
    "    json_list = []\n",
    "\n",
    "    for i in range(len(pages)):\n",
    "        response = requests.get(f\"{url}page={i}&api_key={API_key}\").json()\n",
    "        json_list.append(response)\n",
    "    \n",
    "    player_ids = []\n",
    "\n",
    "    for i in range(1,len(pages)):\n",
    "        for j in range(len(json_list[i])):\n",
    "            if json_list[i][j].get('inactive') == False:\n",
    "                player_ids.append(json_list[i][j]['summonerId'])\n",
    "                \n",
    "    return player_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nowe let's actually get all the ids for players in diamond\n",
    "\n",
    "player_ids_diamond = []\n",
    "\n",
    "for url in urls:\n",
    "    player_ids_diamond.append(get_summoner_ids(pages,url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do the same for master players\n",
    "\n",
    "url_masters = \"https://kr.api.riotgames.com/lol/league/v4/masterleagues/by-queue/RANKED_SOLO_5x5?\"\n",
    "\n",
    "def get_master_ids(url):\n",
    "    \n",
    "    response = requests.get(f\"{url}api_key={API_key}\").json()\n",
    "    player_ids = []\n",
    "    for j in range(len(response['entries'])):\n",
    "        if response['entries'][j].get('inactive') == False:\n",
    "                player_ids.append(response['entries'][j]['summonerId'])\n",
    "    return player_ids\n",
    "\n",
    "master_ids = get_master_ids(url_masters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also need grandmaster ids \n",
    "\n",
    "url_grandmasters = \"https://kr.api.riotgames.com/lol/league/v4/grandmasterleagues/by-queue/RANKED_SOLO_5x5?\"\n",
    "\n",
    "grandmaster_ids = get_master_ids(url_grandmasters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally I want challenger ids \n",
    "\n",
    "url_challenger = \"https://kr.api.riotgames.com/lol/league/v4/challengerleagues/by-queue/RANKED_SOLO_5x5?\"\n",
    "\n",
    "challenger_ids = get_master_ids(url_challenger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have summoner ids, but we actually need puuids to be able to get matchids. We can only get puuids with summonerids, that why we needed them\n",
    "import time\n",
    "\n",
    "def get_puuids(ids, max_retries=5, retry_delay=10):\n",
    "    puuid_ids = []\n",
    "    url = \"https://kr.api.riotgames.com/lol/summoner/v4/summoners/\"\n",
    "    for i in range(len(ids)):\n",
    "        for retry_count in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(f\"{url}{ids[i]}?api_key={API_key}\").json()\n",
    "                puuid_ids.append([ids[i], response[\"puuid\"]])\n",
    "                break  # Exit the retry loop if we got a successful response\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error occurred while fetching puuid for ID {ids[i]}. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                if retry_count == max_retries - 1:\n",
    "                    # If we've exhausted all retries, return the puuid_ids we have collected so far\n",
    "                    print(f\"Failed to fetch puuid for ID {ids[i]}. Moving on...\")\n",
    "                    return puuid_ids\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while fetching puuid for ID {ids[i]}. Moving on...\")\n",
    "                return puuid_ids\n",
    "    return puuid_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting challenger, grandmaster and master puuids \n",
    "\n",
    "challenger_puuid = get_puuids(challenger_ids)\n",
    "grandmaster_puuid = get_puuids(grandmaster_ids)\n",
    "master_puuid = get_puuids(master_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while fetching puuid for ID jeaz-jPScgIQycvHe6Pm-i_kMmdWc9_wPFZzHequkWr0rtfo. Retrying in 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "# i still need diamonds puuids\n",
    "\n",
    "diamond_puuid = []\n",
    "\n",
    "for i in range(len(player_ids_diamond)):\n",
    "    diamond_puuid.append(get_puuids(player_ids_diamond[i]))\n",
    "\n",
    "# only take unique match ids into the list \n",
    "# then from each match id i need to take a list of champions + items that each of those champions built "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing a function that will get me all puids to one array\n",
    "def concat_puuids(d,m,gm,ch):\n",
    "    all_puids = []\n",
    "    \n",
    "    for id in m:\n",
    "        all_puids.append(id)\n",
    "    for id in gm:\n",
    "        all_puids.append(id)\n",
    "    for id in ch:\n",
    "        all_puids.append(id)\n",
    "    for i in range(len(d)):\n",
    "        for j in range(len(d[i])):\n",
    "            all_puids.append(d[i][j][1])\n",
    "\n",
    "    return all_puids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all puids together\n",
    "\n",
    "all_puids = concat_puuids(diamond_puuid,master_puuid,grandmaster_puuid,challenger_puuid)\n",
    "\n",
    "\n",
    "# so far we have 12000 active players, that looks promising - we should be getting about 30 matches on average from each of them which even \n",
    "# in a situation where the matches will double it will still give us a lot of unique matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's export the puuids for the future so we dont have to run the code again with every patch\n",
    "import json\n",
    "\n",
    "def export_to_json(arr, filename):\n",
    "    with open(f'{filename}.json','w') as f:\n",
    "        json.dump(arr, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_json(all_puids, \"puuids_latest_patch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load the puuids\n",
    "\n",
    "import json\n",
    "\n",
    "def load_json(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i need to find match ids for all the puuids \n",
    "\n",
    "\n",
    "def get_match_ids(puuids,max_retries=5, retry_delay=10):\n",
    "\n",
    "    last_patch_date = '1676899200'\n",
    "    match_ids =[]\n",
    "    url = \"https://asia.api.riotgames.com/lol/match/v5/matches/by-puuid/\"\n",
    "\n",
    "    for id in puuids:\n",
    "        for retry_count in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(f\"{url}{id}/ids?startTime={last_patch_date}&start=0&count=30&api_key={API_key}\").json()\n",
    "                match_ids.append(response)\n",
    "                break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error occurred while fetching puuid for ID {id}. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                if retry_count == max_retries - 1:\n",
    "                    # If we've exhausted all retries, return the puuid_ids we have collected so far\n",
    "                    print(f\"Failed to fetch puuid for ID {id}. Moving on...\")\n",
    "                    return match_ids\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while fetching puuid for ID {id}. Moving on...\")\n",
    "                return match_ids\n",
    "    return match_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while fetching puuid for ID XTsa2yO1q3r2VFzvDnyZ6tIwoXrF08IEIodfzgfg46iHytB4hDTjpQlVvb2ycK5JgAhxk5gDrMEnNw. Retrying in 10 seconds...\n",
      "Error occurred while fetching puuid for ID Sa6hAq_4dEo8o0jDpw52BYgiVpRg8KNTXIE7okETrsnqSFSE44nJ6Fq4fFcXBmnkjhgnp16p4q8dOA. Retrying in 10 seconds...\n",
      "Error occurred while fetching puuid for ID ZM7HxuCE9dL09js3Yv8aCwv-qOptUpfCesmWEVRZwiKn7Dbzs2Pl8BhaM2bkKXuXDDl9AXbv2j_bqg. Retrying in 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "# get match ids\n",
    "\n",
    "all_match_ids = get_match_ids(all_puids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, we have almost 200k unique match ids, looking good - we will have a lot of data\n",
    "# first let's load the match ids into json file so we don't lose them\n",
    "\n",
    "export_to_json(unique_match_ids.tolist(), 'match_ids_latest_patch')\n",
    "\n",
    "# let's load the json file with items \n",
    "\n",
    "items = load_json('C:/Users/kaczm/OneDrive/Dokumenty/item.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's eliminate duplicates\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_pure_match_ids(match_ids):\n",
    "    pure_match_ids = []\n",
    "\n",
    "    for i in range(len(match_ids)):\n",
    "        pure_match_ids.append(match_ids[i])\n",
    "            \n",
    "    return np.unique(pure_match_ids) \n",
    "    \n",
    "unique_match_ids = get_pure_match_ids(load_json('match_ids_latest_patch.json'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         dic[key] \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m dic\n\u001b[1;32m----> 9\u001b[0m item_data \u001b[39m=\u001b[39m get_items(\u001b[39m'\u001b[39;49m\u001b[39mC:/Users/kaczm/OneDrive/Dokumenty/item.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m, in \u001b[0;36mget_items\u001b[1;34m(item_json)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_items\u001b[39m(item_json):\n\u001b[0;32m      4\u001b[0m     dic \u001b[39m=\u001b[39m {}\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m item_json[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      6\u001b[0m         dic[key] \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m dic\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# let's get all the items name \n",
    "\n",
    "def get_items(item_json):\n",
    "    dic = {}\n",
    "    for key, value in item_json['data'].items():\n",
    "        dic[key] = value['name']\n",
    "    return dic\n",
    "\n",
    "item_data = get_items('C:/Users/kaczm/OneDrive/Dokumenty/item.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also get rune data\n",
    "\n",
    "def get_runes(rune_json):\n",
    "\n",
    "    dic = {}\n",
    "    with open(rune_json) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for rune in data:\n",
    "        for slot in rune['slots']:\n",
    "            for sub_rune in slot['runes']:\n",
    "                dic[sub_rune['id']] =  sub_rune['name']\n",
    "    return dic\n",
    "\n",
    "rune_data = get_runes('C:/Users/kaczm/OneDrive/Dokumenty/runesReforged.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need the data coming from match_ids\n",
    "# but what do we need, aside from champions played, runes, stats and who won? maybe the blue/red side played? summoner spells i dont think are needed\n",
    "\n",
    "# we will need multiple threads to quicken the execution of the function, as 195k elements would actually get called over 18 days \n",
    "\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_match_data(match_ids, max_retries=5, retry_delay=10, num_threads=1):\n",
    "\n",
    "    participants_data = []\n",
    "\n",
    "    def fetch_match_data(match_id):\n",
    "        for retry_count in range(max_retries):\n",
    "            try:\n",
    "\n",
    "                response = requests.get(f'https://asia.api.riotgames.com/lol/match/v5/matches/{match_id}?api_key={API_key}').json()\n",
    "\n",
    "                for participant in response['info']['participants']:\n",
    "                    participant_data = {\n",
    "                        'kills': participant['kills'],\n",
    "                        'deaths': participant['deaths'],\n",
    "                        'assists': participant['assists'],\n",
    "                        'champion_name': participant['championName'],\n",
    "                        'team_position': participant['teamPosition'],\n",
    "                        'items': [participant['item0'], participant['item1'], participant['item2'], participant['item3'], participant['item4'], participant['item5'], participant['item6']],\n",
    "                        'win': participant['win'],\n",
    "                        'masteries': {\n",
    "                            'primary_master': participant['perks']['styles'][0]['selections'][0]['perk'],\n",
    "                            'primary_master_sub_1': participant['perks']['styles'][0]['selections'][1]['perk'],\n",
    "                            'primary_master_sub_2': participant['perks']['styles'][0]['selections'][2]['perk'],\n",
    "                            'primary_master_sub_3': participant['perks']['styles'][0]['selections'][3]['perk'],\n",
    "                            'secondary_mastery': participant['perks']['styles'][1]['selections'][0]['perk'],\n",
    "                            'secondary_mastery_sub_1': participant['perks']['styles'][1]['selections'][1]['perk']\n",
    "                        }\n",
    "                    }\n",
    "                    participants_data.append(participant_data)\n",
    "                break \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error occurred while fetching match ids for ID {match_id}. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                if retry_count == max_retries - 1:\n",
    "                    # If we've exhausted all retries, return None\n",
    "                    print(f\"Failed to fetch match id for ID {match_id}. Moving on...\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred while fetching match id for ID {match_id}. Moving on...\")\n",
    "                return participants_data\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        future_to_match_id = {executor.submit(fetch_match_data, match_id): match_id for match_id in match_ids}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(future_to_match_id):\n",
    "            match_id = future_to_match_id[future]\n",
    "            participant_data = future.result()\n",
    "            if participant_data is not None:\n",
    "                participants_data.append(participant_data)\n",
    "\n",
    "    return participants_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while fetching match ids for ID KR_6418184376. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418329042. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418390951. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418411271. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418413563. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418430462. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418433221. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418452216. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418509885. Retrying in 10 seconds...\n",
      "Error occurred while fetching match ids for ID KR_6418530603. Retrying in 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "players_data_batch_one = get_match_data(unique_match_ids[170000:190000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199991"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(players_data_batch_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62290"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(players_data_batch_one[137701:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163766"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(unique_match_ids).index('KR_6417436762')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_json(players_data_batch_one[137701:], 'players_match_data_thirteen')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_prj-SRynVlFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34304ceff4189be5ec3888addaf2a860e88df2f436b7958182f0d19632a0f568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
